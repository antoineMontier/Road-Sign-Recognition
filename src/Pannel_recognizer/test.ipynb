{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that you have your images in a directory structure where each category has its own folder\n",
    "data_dir = './../../Training/augmentation1/'  # Replace with the path to your dataset directory\n",
    "\n",
    "# Image dimensions and batch size\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 8\n",
    "\n",
    "# Data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # using 20% of the data for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 924 images belonging to 6 classes.\n",
      "Found 228 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Train dataset generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # set as training data\n",
    ")\n",
    "\n",
    "# Validation dataset generator\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # set as validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')  # Adjust the number of neurons to match the number of classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint( \"./../../models/new-model.h5\" , monitor='val_accuracy', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - ETA: 0s - loss: 1.4332 - accuracy: 0.4236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoine/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 112s 960ms/step - loss: 1.4332 - accuracy: 0.4236 - val_loss: 1.1801 - val_accuracy: 0.5089\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 126s 1s/step - loss: 0.9430 - accuracy: 0.6070 - val_loss: 0.8893 - val_accuracy: 0.6250\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 120s 1s/step - loss: 0.8853 - accuracy: 0.6539 - val_loss: 0.8753 - val_accuracy: 0.6830\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 120s 1s/step - loss: 0.7882 - accuracy: 0.6889 - val_loss: 0.8086 - val_accuracy: 0.6920\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 118s 1s/step - loss: 0.7589 - accuracy: 0.6812 - val_loss: 1.0242 - val_accuracy: 0.6116\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 131s 1s/step - loss: 0.6690 - accuracy: 0.7227 - val_loss: 0.6355 - val_accuracy: 0.7946\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 130s 1s/step - loss: 0.5521 - accuracy: 0.7784 - val_loss: 0.5665 - val_accuracy: 0.7812\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 168s 1s/step - loss: 0.5140 - accuracy: 0.8079 - val_loss: 0.6739 - val_accuracy: 0.7902\n",
      "Epoch 9/100\n",
      " 73/115 [==================>...........] - ETA: 1:04 - loss: 0.5800 - accuracy: 0.7962"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
    "print(f'Validation accuracy: {val_accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
